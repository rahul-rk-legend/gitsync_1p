{
    "name": "projects/project/locations/location/instances/instance/integrations/Siemplify/jobs/6/jobInstances/16",
    "id": 0,
    "job": "Cases Collector",
    "integration": "Siemplify",
    "createTime": 1764135885341,
    "updateTime": 1764135887939,
    "custom": false,
    "script": "import datetime\nimport gzip\nimport io\nimport json\nimport os\nimport re\nimport uuid\n\nfrom SiemplifyJob import SiemplifyJob\nfrom SiemplifyUtils import output_handler\n\nfrom PublisherAPIManager import PublisherAPIManager\nfrom SiemplifyExceptions import SiemplifyHttpError\nfrom utils import is_supported_siemplify_version\n\n\nCASE_SUFFIX = \".case\"\nLOGS_SUFFIX = \".conn_log\"\nLIN_CASES_FOLDER = r\"/i/Siemplify_Channels/Cases\"\nLIN_LOGS_FOLDER = r\"/i/Siemplify_Channels/ConnectorsLog\"\nWIN_CASES_FOLDER = r\"I:\\Siemplify_Channels\\Cases\"\nWIN_LOGS_FOLDER = r\"I:\\Siemplify_Channels\\ConnectorsLog\"\nSUPPORTED_BULK_MIN_VER = (1, 3, 2)\n\nREMOTE_CONNECTOR_DEBUG_OUTPUT = \"Debug output is not available on remote connectors.\"\n\n\ndef gzip_content(content):\n    \"\"\"\n    Gzip given content and returned the compresses data\n    :param content: {string}\n    :return: {stringIO} Byte array of the compresses content\n    \"\"\"\n    out = io.StringIO()\n    with gzip.GzipFile(fileobj=out, mode=\"w\") as f:\n        f.write(content)\n    return out.getvalue()\n\n\ndef create_package_name(connector_id, package_suffix):\n    \"\"\"\n    Generate package delivery path by given extension and connector id\n    :param connector_id: {string} The connector identifier\n    :param package_suffix: {string} (.case, .conn_log)\n    :return: {string} package name\n    \"\"\"\n    cycle_id = str(uuid.uuid4())\n    return f\"{connector_id}_{cycle_id}{package_suffix}\"\n\n\ndef create_log_file(logs_folder_path, connector_id, log_package):\n    \"\"\"\n    Write logs package object to given path\n    :param logs_folder_path: {str} The logs folder path\n    :param connector_id: {string} The id of the connector\n    :param log_package: {dict} The logs package\n    \"\"\"\n    # Write the case packet to path\n    package_name = create_package_name(connector_id, LOGS_SUFFIX)\n    log_package_path = os.path.join(logs_folder_path, package_name)\n\n    # Write log package to path\n    with open(log_package_path, \"wb\") as log_package_file:\n        compressed_log_package = gzip_content(json.dumps(log_package))\n        log_package_file.write(compressed_log_package)\n\n\ndef underscore_to_camel(name):\n    under_pat = re.compile(r\"_([a-z])\")\n    return under_pat.sub(lambda x: x.group(1).upper(), name)\n\n\ndef format_attachment(attachments):\n    new_attachments = []\n    for attachment in attachments:\n        new_attachment = {}\n        for key, val in list(attachment.items()):\n            new_attachment[underscore_to_camel(key)] = val\n        new_attachments.append(new_attachment)\n\n    return new_attachments\n\n\ndef send_ack(siemplify, publisher_api_manager, connector_package, cert_file_content):\n    # TEST ACK TASK\n    siemplify.LOGGER.info(\"Sending Ack Task.\")\n    try:\n        publisher_api_manager.send_ack_task(connector_package, cert_file_content)\n        siemplify.LOGGER.info(\"Sent Ack Task for package\")\n    except Exception as e:\n        siemplify.LOGGER.error(\"Failed to send Ack Task.\")\n        siemplify.LOGGER.exception(e)\n\n\ndef send_bulk_acks(\n    siemplify,\n    publisher_api_manager,\n    connector_package,\n    cert_file_content,\n    publisher_cert_file_content=None,\n):\n    siemplify.LOGGER.info(\"Sending bulk Ack Tasks.\")\n    try:\n        publisher_api_manager.send_bulk_ack_tasks(\n            connector_package, cert_file_content, publisher_cert_file_content\n        )\n        siemplify.LOGGER.info(\"Sent bulk Ack Tasks for all finished packages\")\n    except Exception as e:\n        siemplify.LOGGER.error(\"Failed to send Ack Task.\")\n        siemplify.LOGGER.exception(e)\n\n\ndef create_case_file(cases_folder_path, connector_id, cases_package):\n    \"\"\"\n    Write cases package to a given path\n    :param cases_folder_path: {str} The Cases folder path\n    :param connector_id: {str} The id of the connector\n    :param cases_package: {dict} The cases package\n    \"\"\"\n    for case in cases_package.get(\"Cases\", []):\n        # Generate case unique name and form path.\n        package_name = create_package_name(connector_id, CASE_SUFFIX)\n        case_package_path = os.path.join(cases_folder_path, package_name)\n        attachments = case.get(\"Attachments\")\n        if attachments:\n            case[\"Attachments\"] = format_attachment(attachments)\n\n        # Construct and Write Alert to file.\n        with open(case_package_path, \"w\") as case_package_file:\n            case_package_file.write(\n                json.dumps(\n                    {\n                        \"Cases\": [case],\n                        \"ConnectorIdentifier\": cases_package.get(\"ConnectorIdentifier\"),\n                        \"IsTestCase\": False,\n                        \"DebugOutput\": REMOTE_CONNECTOR_DEBUG_OUTPUT,\n                    }\n                )\n            )\n\n\ndef bulk_execution(\n    siemplify,\n    publisher_id,\n    publisher_api_manager,\n    publisher_cert_file_content,\n    agent_certs_cache,\n):\n    try:\n        if datetime.datetime.utcnow().time().minute in {0, 30}:\n            publisher_api_manager.delete_old_packages()\n    except Exception as e:\n        siemplify.LOGGER.error(\n            f\"failed to delete old connector packages from publisher. Exception: {e}\"\n        )\n        pass\n\n    connector_packages = publisher_api_manager.fetch_connector_packages(limit=50)\n    agents_finished_packages = {}\n    finished_packages_ids = []\n    connector_keys = siemplify.get_remote_connector_keys_map(publisher_id)\n    for connector_package in connector_packages:\n        try:\n            connector_id = connector_package.get(\"connector_id\")\n            siemplify.LOGGER.info(\n                f\"Decrypting package {connector_package.get('id')} for connector {connector_id} \\n\"\n            )\n            agent_id = connector_package.get(\"agent\")\n            if not publisher_cert_file_content:\n                if not agent_certs_cache.get(agent_id):\n                    agent_details = siemplify.get_agent_by_id(agent_id)\n                    cert_file_content = agent_details.get(\"certificate\")\n                    agent_certs_cache[agent_id] = cert_file_content\n\n            package = publisher_api_manager.decrypt_connector_package(\n                encryption_key=connector_keys[connector_id],\n                connector_package=connector_package.get(\"package\"),\n            )\n\n            package = json.loads(package)\n\n            cases_package = package.get(\"cases_package\")\n            logs_package = package.get(\"logs_package\")\n\n            # Create the cases and logs files to ingest to\n\n            # fix_paths\n            if \"win\" in os.environ.get(\"OS\", \"\").lower():\n                cases_folder = WIN_CASES_FOLDER\n                logs_folder = WIN_LOGS_FOLDER\n            else:\n                cases_folder = LIN_CASES_FOLDER\n                logs_folder = LIN_LOGS_FOLDER\n\n            # Siemplify\n            siemplify.LOGGER.info(\"Creating cases from package.\")\n            create_case_file(cases_folder, connector_id, cases_package)\n\n            siemplify.LOGGER.info(\"Creating logs from package.\")\n            create_log_file(logs_folder, connector_id, logs_package)\n\n            if not agents_finished_packages.get(agent_id):\n                agents_finished_packages[agent_id] = {\"packages\": [connector_package]}\n            else:\n                agents_finished_packages[agent_id][\"packages\"].append(connector_package)\n            finished_packages_ids.append(connector_package.get(\"id\"))\n\n        except Exception as e:\n            siemplify.LOGGER.error(\n                f\"Failed to process package {connector_package.get('id')} for connector {connector_id}. \\n\"\n            )\n            siemplify.LOGGER.exception(e)\n\n    try:\n        # Send packages ack back:\n        siemplify.LOGGER.info(\n            f\"Sending case acks for packages: {' '.join(str(x) for x in finished_packages_ids)} \\n\"\n        )\n        send_bulk_acks(\n            siemplify,\n            publisher_api_manager,\n            agents_finished_packages,\n            agent_certs_cache,\n            publisher_cert_file_content,\n        )\n\n        # Delete the package from the publisher\n        siemplify.LOGGER.info(\n            f\"Deleting ingested connector packages: {' '.join(str(x) for x in finished_packages_ids)} \\n\"\n        )\n        publisher_api_manager.delete_bulk_connector_packages(finished_packages_ids)\n\n    except Exception as e:\n        siemplify.LOGGER.error(\n            \"An error occurred while Deleting ingested connector packages. \\n\"\n        )\n        siemplify.LOGGER.exception(e)\n\n\ndef one_by_one_execution(\n    siemplify,\n    publisher_id,\n    publisher_api_manager,\n    publisher_cert_file_content,\n    agent_certs_cache,\n):\n    try:\n        connector_keys = siemplify.get_remote_connector_keys_map(publisher_id)\n        for connector_id, encryption_key in list(connector_keys.items()):\n            try:\n                siemplify.LOGGER.info(f\"Fetching packages for connector {connector_id}\")\n\n                # Get packages.\n                connector_packages = publisher_api_manager.fetch_connector_packages(\n                    connector_id=connector_id\n                )\n                for connector_package in connector_packages:\n                    try:\n                        siemplify.LOGGER.info(\n                            f\"Decrypting package {connector_package.get('id')}\"\n                        )\n                        if not publisher_cert_file_content:\n                            agent_id = connector_package.get(\"agent\")\n                            if agent_certs_cache.get(agent_id):\n                                cert_file_content = agent_certs_cache[agent_id]\n                            else:\n                                agent_details = siemplify.get_agent_by_id(agent_id)\n                                cert_file_content = agent_details.get(\"certificate\")\n                                agent_certs_cache[agent_id] = cert_file_content\n                        else:\n                            cert_file_content = publisher_cert_file_content\n                        package = publisher_api_manager.decrypt_connector_package(\n                            encryption_key=encryption_key,\n                            connector_package=connector_package.get(\"package\"),\n                        )\n\n                        package = json.loads(package)\n\n                        cases_package = package.get(\"cases_package\")\n                        logs_package = package.get(\"logs_package\")\n\n                        # Create the cases and logs files to ingest to\n\n                        # fix_paths\n                        if \"win\" in os.environ.get(\"OS\", \"\").lower():\n                            cases_folder = WIN_CASES_FOLDER\n                            logs_folder = WIN_LOGS_FOLDER\n                        else:\n                            cases_folder = LIN_CASES_FOLDER\n                            logs_folder = LIN_LOGS_FOLDER\n\n                        # Siemplify\n                        siemplify.LOGGER.info(\"Creating cases from package.\")\n                        create_case_file(cases_folder, connector_id, cases_package)\n\n                        siemplify.LOGGER.info(\"Creating logs from package.\")\n                        create_log_file(logs_folder, connector_id, logs_package)\n\n                        # Send package ack back:\n                        send_ack(\n                            siemplify,\n                            publisher_api_manager,\n                            connector_package,\n                            cert_file_content,\n                        )\n\n                        # Delete the package from the publisher\n                        siemplify.LOGGER.info(\n                            f\"Deleting package {connector_package.get('id')}\"\n                        )\n                        publisher_api_manager.delete_connector_package(\n                            connector_package.get(\"id\")\n                        )\n\n                    except Exception as e:\n                        siemplify.LOGGER.error(\n                            f\"Failed to process package {connector_package.get('id')}\"\n                        )\n                        siemplify.LOGGER.exception(e)\n\n            except Exception as e:\n                siemplify.LOGGER.error(\n                    f\"Failed to process packages of connector {connector_id}\"\n                )\n                siemplify.LOGGER.exception(e)\n\n        siemplify.LOGGER.info(\"----Cases Collector finished---\")\n\n    except Exception as e:\n        siemplify.LOGGER.error(\"An error occurred while running Cases Collector\")\n        siemplify.LOGGER.exception(e)\n        raise e\n\n\n@output_handler\ndef main():\n    siemplify = SiemplifyJob()\n    try:\n        siemplify.script_name = \"Cases Collector\"\n        verify_ssl = (\n            str(siemplify.parameters.get(\"Verify SSL\")).lower() == str(True).lower()\n        )\n        siemplify.LOGGER.info(\"----Cases Collector started---\")\n        publisher_id = siemplify.parameters.get(\"Publisher Id\")\n        publisher_details = siemplify.get_publisher_by_id(publisher_id)\n        publisher_api_root = publisher_details[\"server_api_root\"]\n        api_token = publisher_details[\"api_token\"]\n        publisher_cert_file_content = None\n        if not \"get_agent_by_id\" in dir(\n            siemplify\n        ):  # Valid method for 5.5.3-hf-8 & 5.6.0-hf-2 and higher versions\n            publisher_cert_file_content = publisher_details.get(\"certificate\")\n        agent_certs_cache = {}\n        publisher_api_manager = PublisherAPIManager(\n            publisher_api_root, api_token, verify_ssl\n        )\n\n        try:\n            current_version = publisher_api_manager.get_pub_version()\n            bulk_methods = is_supported_siemplify_version(\n                version=current_version,\n                min_version=SUPPORTED_BULK_MIN_VER,\n            )\n        except SiemplifyHttpError:\n            bulk_methods = False\n\n        if bulk_methods:\n            # Supported endpoints from Publisher 1.3.2\n\n            bulk_execution(\n                siemplify,\n                publisher_id,\n                publisher_api_manager,\n                publisher_cert_file_content,\n                agent_certs_cache,\n            )\n\n        else:\n            # Old behavior before Publisher 1.3.2\n            one_by_one_execution(\n                siemplify,\n                publisher_id,\n                publisher_api_manager,\n                publisher_cert_file_content,\n                agent_certs_cache,\n            )\n\n    except Exception as e:\n        siemplify.LOGGER.error(\"An error occurred while running Cases Collector\")\n        siemplify.LOGGER.exception(e)\n        raise e\n\n    if siemplify.LOGGER.error_logged:\n        raise Exception(\"Error was logged during execution, check the logs.s\")\n\n    siemplify.LOGGER.info(\n        \"-----Cases Collector has finished execution without errors----\"\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "author": "Siemplify System",
    "lastRunStatus": "Error",
    "lastRunTime": 1764135887917,
    "uniqueIdentifier": "b9203d69-554a-4a49-b58c-a36cac496df1",
    "enabled": false,
    "displayName": "Cases Collector",
    "description": "Collect cases and connector logs from Publisher.",
    "intervalSeconds": 3600,
    "advanced": false
}